{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finnhub as fh\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas_datareader as pdr\n",
    "import quandl\n",
    "import time\n",
    "import datetime\n",
    "from datetime import timezone\n",
    "import scipy.stats\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "Below are the functions used to gather price and financial statement data from YahooFinance, FinnHub and Robur Global using their respective APIs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas DF manipulation helper functions\n",
    "def DateToUnix(date):\n",
    "    return int(date.replace(tzinfo=timezone.utc).timestamp())\n",
    "\n",
    "def UnixToDate(unix):\n",
    "    return datetime.datetime.utcfromtimestamp(unix).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def FlattenStatementDF(statement_df):\n",
    "    list_of_dict = list(statement_df.financials)\n",
    "    return pd.DataFrame(list_of_dict)\n",
    "\n",
    "def MergeStatementDF(statement_df_list):\n",
    "    output = statement_df_list[0].merge(statement_df_list[1],on=\"period\")\n",
    "    output = output.merge(statement_df_list[2],on=\"period\")\n",
    "    output = output.set_index('period')\n",
    "    return output\n",
    "\n",
    "def SaveOutput(filename_prefix,**kwargs):\n",
    "    for df_name, df in kwargs.items():\n",
    "        filename = filename_prefix + '_' + df_name + '.csv'\n",
    "        df.to_csv(filename)\n",
    "        \n",
    "def GetFailedCompanies(failed_ticker_list,ticker_company_table,reason_failed):\n",
    "    print(\"Couldn't get\",reason_failed,\"data for\",len(failed_ticker_list),\"companies.\")\n",
    "    output = pd.DataFrame(columns=['ticker','company','reason_failed'])\n",
    "    for ticker in failed_ticker_list:\n",
    "        company = ticker_company_table.company.loc[ticker_company_table.finnhub == ticker]\n",
    "        row = {'ticker':ticker,'company':company,'reason_failed':reason_failed}\n",
    "        output = output.append(row,ignore_index=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FinnHub\n",
    "finnhub_client = fh.Client(api_key=\"br4je57rh5r8ufeothr0\")\n",
    "\n",
    "def GetFinnHubPrice(client,ticker,start_unix,end_unix):\n",
    "    candles = client.stock_candles(ticker, 'D', start_unix, end_unix)\n",
    "    if candles['s'] == 'no_data':\n",
    "        print(\"Could not find price data for\",ticker)\n",
    "        return None\n",
    "    else:\n",
    "        return pd.DataFrame(candles)\n",
    "\n",
    "def GetFinnHubFinancials(client,ticker,frequency,backtest_start_date):\n",
    "    def _GetRelevantStatementIndex_(statement_df,backtest_start_date):\n",
    "        # Flag if date of statement is within backtesting period\n",
    "        def CheckDate(date_to_check,date_window):\n",
    "            date_to_check = datetime.strptime(date_to_check, '%Y-%m-%d')\n",
    "            return date_to_check >= date_window\n",
    "        \n",
    "        index = 0\n",
    "        while index < len(statement_df):\n",
    "            statement_date = statement_df.iloc[index][0]['period']\n",
    "            if CheckDate(statement_date,backtest_start_date):\n",
    "                index += 1\n",
    "            else:\n",
    "                return index + 1 # Include first statement out of period\n",
    "        return index\n",
    "    \n",
    "    statement_type_list = ['bs','ic','cf']\n",
    "    statement_df_list = []\n",
    "    for statement_type in statement_type_list:\n",
    "        statement_data_full = client.financials(ticker,statement_type,frequency)\n",
    "        if statement_data_full['financials'] is None:\n",
    "            print(\"Could not find financial data for\",ticker)\n",
    "            return None\n",
    "        else:\n",
    "            statement_data_full = pd.DataFrame(statement_data_full)\n",
    "            statement_relevant_index = _GetRelevantStatementIndex_(statement_data_full,backtest_start_date)\n",
    "            statement_data_relevant = statement_data_full.iloc[:statement_relevant_index]\n",
    "            statement_df_list.append(FlattenStatementDF(statement_data_relevant))\n",
    "    return MergeStatementDF(statement_df_list)\n",
    "\n",
    "def GetISIN(ticker):\n",
    "    company_profile = finnhub_client.company_profile(symbol=ticker)\n",
    "    if len(company_profile) > 0:\n",
    "        return company_profile['isin']\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robur\n",
    "def GetRoburCompanyCode(isin):\n",
    "    robur_search = robur_codes_df.company_code.loc[robur_codes_df.isin_code == isin]\n",
    "    if len(robur_search) > 0:\n",
    "        return robur_search.iloc[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def GetRoburCompanyCode(ticker,robur_mapped_code_df):\n",
    "    code_search = robur_mapped_code_df.robur_code.loc[robur_mapped_code_df.ticker == ticker]\n",
    "    if len(code_search) > 0:\n",
    "        return code_search.iloc[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def GetQuandlCode(company_code,financial_statement):\n",
    "    return \"RB1/{company_code}_HY{financial_statement}\".format(company_code=company_code,financial_statement=financial_statement)\n",
    "\n",
    "def DownloadRoburFinancials(company_code):\n",
    "    statement_df_list = []\n",
    "    for statement in robur_statements:\n",
    "        quandl_code = GetQuandlCode(company_code,statement)\n",
    "        statement_data = quandl.get(quandl_code,\n",
    "                                    start_date = backtest_start_date,\n",
    "                                    end_date = backtest_end_date)\n",
    "        statement_df_list.append(statement_data)\n",
    "    return MergeStatementDF(statement_df_list)\n",
    "\n",
    "def MapRoburCodes(ticker_df):\n",
    "    robur_code_mapping = pd.DataFrame(columns=['ticker','robur_code'])\n",
    "    ticker_count = 0\n",
    "    for ticker in ticker_df.finnhub:\n",
    "        row = {}\n",
    "        print(\"Checking\",ticker)\n",
    "        row['ticker'] = ticker\n",
    "        isin = GetISIN(ticker)\n",
    "        ticker_count += 1\n",
    "        if (ticker_count+1) % 30 == 0:\n",
    "            time.sleep(60)\n",
    "        if isin is not None:\n",
    "            robur_company_code = GetRoburCompanyCode(isin)\n",
    "            if robur_company_code is not None:\n",
    "                row['robur_code'] = robur_company_code\n",
    "            else:\n",
    "                row['robur_code'] = 'N/A'\n",
    "        else:\n",
    "            row['robur_code'] = 'N/A'\n",
    "        robur_code_mapping = robur_code_mapping.append(row,ignore_index=True)\n",
    "    return robur_code_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factors class\n",
    "class Company():\n",
    "    def __init__(self,ticker,financials_df,share_price,data_source):\n",
    "        self.share_price = share_price # Need to get latest price for share price\n",
    "        self.ticker = ticker\n",
    "        \n",
    "        if data_source == 'fh':\n",
    "            self.revenue = self.ValidateInput('revenue',financials_df)\n",
    "            self.net_income = self.ValidateInput('netIncome',financials_df)\n",
    "            self.total_assets = self.ValidateInput('totalAssets',financials_df)\n",
    "            self.total_debt = self.ValidateInput('totalDebt',financials_df)\n",
    "            self.shareholder_equity = self.total_assets - self.total_debt\n",
    "            self.operating_cash_flow = self.ValidateInput('cashfromOperatingActivities',financials_df)\n",
    "            self.ebitda = self.ValidateInput('netIncomeBeforeTaxes',financials_df)\n",
    "            self.shares_outstanding = self.ValidateInput('totalCommonSharesOutstanding',financials_df)\n",
    "            self.dividend_yield = self.ValidateInput('totalCashDividendsPaid',financials_df) / self.shares_outstanding\n",
    "            self.market_cap = self.shares_outstanding * self.share_price\n",
    "            self.cash_and_equivalents = self.ValidateInput('cash',financials_df) + self.ValidateInput('cashEquivalents',financials_df)\n",
    "            self.enterprise_value = self.market_cap + self.total_debt + self.cash_and_equivalents\n",
    "            self.book_value = self.shares_outstanding * self.ValidateInput('tangibleBookValueperShare',financials_df)\n",
    "        elif data_source == 'rb':\n",
    "            self.net_income = financials_df['Net Income exc. extra'],\n",
    "            self.total_assets = financials_df['Total Assets'],\n",
    "            self.total_debt = financials_df['Total Liabilities'],\n",
    "            self.shareholder_equity = self.total_assets - self.total_debt,\n",
    "            self.operating_cash_flow = financials_df['Cash from Operations'],\n",
    "            self.ebitda = financials_df['Operating Income']\n",
    "            self.shares_outstanding = financials_df['Diluted Shares OS']\n",
    "            self.market_cap = self.shares_outstanding * share_price\n",
    "            self.cash_and_equivalents = financials_df['End Cash']\n",
    "            self.enterprise_value = self.market_cap + self.total_debt + self.cash_and_equivalents\n",
    "            self.book_value = financials_df['Shareholder Equity']\n",
    "        else:\n",
    "            print(\"Data source not recognised\")\n",
    "            \n",
    "    def ValidateInput(self,variable_name,input_df):\n",
    "        input_df = input_df.fillna(0)\n",
    "        return input_df[variable_name]\n",
    "    \n",
    "    def EquityQuality(self):\n",
    "        metrics = {'return_on_equity' : [self.net_income / self.shareholder_equity],\n",
    "               'cash_flow_to_assets' : [self.operating_cash_flow / self.total_assets],\n",
    "               'debt_to_earnings' : [self.total_debt / self.ebitda],\n",
    "               'asset_leverage' : [self.total_debt / self.total_assets]\n",
    "               }\n",
    "        return pd.DataFrame.from_dict(metrics)\n",
    "    \n",
    "    def EquitySize(self):\n",
    "        metrics = {'market_cap' : [self.market_cap],\n",
    "               'enterprise_value' : [self.enterprise_value],\n",
    "               'total_assets' : [self.total_assets]\n",
    "               }\n",
    "        return pd.DataFrame(metrics)\n",
    "    \n",
    "    def EquityValue(self):\n",
    "        metrics = {'dividend_yield' : [self.dividend_yield],\n",
    "                   'earnings_to_price' : [(self.net_income / self.shares_outstanding) / self.share_price],\n",
    "                   'book_to_price' : [(self.book_value / self.shares_outstanding) / self.share_price],\n",
    "                   'sales_to_price' : [(self.revenue / self.shares_outstanding) / self.share_price],\n",
    "                   'enterprise_to_ebitda' : [self.enterprise_value / self.ebitda]\n",
    "            }\n",
    "        return pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor calculation functions\n",
    "def CalculateDailyFactors(ticker_list,unix_date,financials_df,price_df,robur_codes_df):\n",
    "    \n",
    "    quality_df = pd.DataFrame()\n",
    "    value_df = pd.DataFrame()\n",
    "    size_df = pd.DataFrame()\n",
    "    for ticker in ticker_list:\n",
    "        print(ticker)\n",
    "        company_price = GetCompanyPriceFromDF(ticker,unix_date,price_df)\n",
    "        company_share_price = company_price.o\n",
    "        date_time = UnixToDate(unix_date)\n",
    "        company_financials = GetCompanyFinancialsFromDF(ticker,date_time,financials_df)\n",
    "        if company_financials is not None:\n",
    "            company = Company(ticker,company_financials,company_share_price,'fh')\n",
    "            company_quality = company.EquityQuality()\n",
    "            company_value = company.EquityValue()\n",
    "            company_size = company.EquitySize()\n",
    "            company_quality['ticker'] = ticker\n",
    "            company_value['ticker'] = ticker\n",
    "            company_size['ticker'] = ticker\n",
    "            quality_df = quality_df.append(company_quality)\n",
    "            value_df = value_df.append(company_value)\n",
    "            size_df = size_df.append(company_size)\n",
    "        else:\n",
    "            print(\"No financial data for\",ticker)\n",
    "            robur_company_code = GetRoburCompanyCode(ticker,robur_codes_df)\n",
    "            if pd.isnull(robur_company_code):\n",
    "                print(\"Could not find robur code\")\n",
    "            else:\n",
    "                print(\"Retrieving robur financial data\")\n",
    "    return quality_df, value_df, size_df\n",
    "\n",
    "def CalculateZScore(column_df):\n",
    "    return stats.zscore(column_df)\n",
    "\n",
    "def WeightFactorConstituents(factor_df):\n",
    "    # Calculate z-scores for each indicator\n",
    "    z_score_df = pd.DataFrame()\n",
    "    for indicator_column in factor_df:\n",
    "        indicator_z_score = CalculateZScore(factor_df[indicator_column])\n",
    "        z_score_df[indicator_column] = indicator_z_score\n",
    "    z_score_df = z_score_df.set_index(factor_df.index)\n",
    "    \n",
    "    # Calculate weighting for company based on z-scores of indicators\n",
    "    z_score_df['summed_z_score'] = z_score_df.sum(axis=1)\n",
    "    summed_z_score_mean = z_score_df['summed_z_score'].mean()\n",
    "    summed_z_score_stdev = statistics.stdev(z_score_df['summed_z_score'])\n",
    "    z_score_df['cdf'] = scipy.stats.norm(summed_z_score_mean, summed_z_score_stdev).cdf(z_score_df['summed_z_score'])\n",
    "    z_score_df['weight'] = z_score_df['cdf'] / sum(z_score_df['cdf'])\n",
    "    return z_score_df['weight']\n",
    "\n",
    "def RankComponents(*args):\n",
    "    max_length = max(len(t) for t in args)\n",
    "    final_rank = np.zeros(max_length)\n",
    "    for column in args:\n",
    "        column_ranked = column.rank(numeric_only=True,na_option='keep',ascending=True)\n",
    "        final_rank += column_ranked\n",
    "    return final_rank / (max_length  + 1)\n",
    "        \n",
    "def UpperDecile(df,factor_column_name):\n",
    "    upper_decile_index = df.quantile(.9)[factor_column_name]\n",
    "    output = df.iloc[int(upper_decile_index):]\n",
    "    return output\n",
    "\n",
    "def LowerDecile(df,factor_column_name):\n",
    "    lower_decile_index = df.quantile(.1)[factor_column_name]\n",
    "    output = df.iloc[:int(lower_decile_index)]\n",
    "    return output\n",
    "\n",
    "# Data extraction helper functions\n",
    "def GetCompanyFinancialsFromDF(ticker,date_time,financial_df):\n",
    "    released_financials_df = financial_df.loc[(financial_df.ticker == ticker) & (financial_df.period < date_time)]\n",
    "    if len(released_financials_df) > 0:\n",
    "        return released_financials_df.iloc[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def GetCompanyPriceFromDF(ticker,unix_date,price_df):\n",
    "    return price_df.loc[(price_df.ticker == ticker) & (price_df.t == unix_date)].iloc[0].loc[['c','h','l','o','t','v']]\n",
    "\n",
    "def GetLongestTimeSeriesTicker(ticker_list,price_df):\n",
    "    length_ticker = {}\n",
    "    for ticker in ticker_list:\n",
    "        length_ticker.__setitem__(ticker, len(price_data.t.loc[price_data.ticker == ticker]))\n",
    "    return max(length_ticker,key = length_ticker.get)\n",
    "\n",
    "def GetDailyTickers(price_df,unix_date):\n",
    "    return list(set(price_data.ticker.loc[price_data.t == unix_date]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation\n",
    "markets = ['HK','L','CO','MI','US']\n",
    "investment_universe = pd.concat(pd.read_excel('investment_universe.xlsx', sheet_name=None), ignore_index=True)\n",
    "robur_codes_map = pd.read_csv('robur_codes_mapped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating 2019-07-01 07:00:00\n",
      "HILS.L\n",
      "HSX.L\n",
      "ASL.L\n",
      "PHP.L\n",
      "MDC.L\n",
      "HAS.L\n",
      "SAFE.L\n",
      "QLT.L\n",
      "AGT.L\n",
      "MKS.L\n",
      "HMSO.L\n",
      "SIG.L\n",
      "OXIG.L\n",
      "DPLM.L\n",
      "SXS.L\n",
      "WKP.L\n",
      "EWI.L\n",
      "VOF.L\n",
      "RAT.L\n",
      "POG.L\n",
      "CNE.L\n",
      "BEZ.L\n",
      "UKCM.L\n",
      "BCPT.L\n",
      "PZC.L\n",
      "SPT.L\n",
      "IHP.L\n",
      "PFG.L\n",
      "KAZ.L\n",
      "VEIL.L\n",
      "ELM.L\n",
      "FRAS.L\n",
      "888.L\n",
      "STOB.L\n",
      "TUI.L\n",
      "SBRE.L\n",
      "PPH.L\n",
      "BRW.L\n",
      "PETS.L\n",
      "CAPC.L\n",
      "OSB.L\n",
      "FGT.L\n",
      "GFS.L\n",
      "JUST.L\n",
      "JAM.L\n",
      "AML.L\n",
      "SONG.L\n",
      "JII.L\n",
      "FXPO.L\n",
      "UTG.L\n",
      "WEIR.L\n",
      "SYNT.L\n",
      "FCIT.L\n",
      "GRG.L\n",
      "EQN.L\n",
      "BAKK.L\n",
      "IPO.L\n",
      "INVP.L\n",
      "LMP.L\n",
      "RNK.L\n",
      "JMG.L\n",
      "MCRO.L\n",
      "FCH.L\n",
      "HRI.L\n",
      "ENOG.L\n",
      "POLY.L\n",
      "HYVE.L\n",
      "IEM.L\n",
      "CBG.L\n",
      "JLEN.L\n",
      "BBGI.L\n",
      "EZJ.L\n",
      "IGG.L\n",
      "TPK.L\n",
      "EMG.L\n",
      "NEX.L\n",
      "GAW.L\n",
      "GCP.L\n",
      "MYI.L\n",
      "MARS.L\n",
      "VSVS.L\n",
      "AVON.L\n",
      "PLUS.L\n",
      "INPP.L\n",
      "PAGE.L\n",
      "ASHM.L\n",
      "BAG.L\n",
      "JFJ.L\n",
      "AVST.L\n",
      "TALK.L\n",
      "AGR.L\n",
      "HSV.L\n",
      "SNR.L\n",
      "CLI.L\n",
      "HWDN.L\n",
      "BRSC.L\n",
      "TED.L\n",
      "WWH.L\n",
      "No financial data for WWH.L\n",
      "Could not find robur code\n",
      "CSP.L\n",
      "BGFD.L\n",
      "AJB.L\n",
      "BIFF.L\n",
      "BGSC.L\n",
      "HVPE.L\n",
      "FCSS.L\n",
      "GFTU.L\n",
      "SOI.L\n",
      "No financial data for SOI.L\n",
      "Could not find robur code\n",
      "ICP.L\n",
      "PAY.L\n",
      "VTY.L\n",
      "PTEC.L\n",
      "JUP.L\n",
      "BAB.L\n",
      "RSE.L\n",
      "SMWH.L\n",
      "SHB.L\n",
      "FSFL.L\n",
      "GNC.L\n",
      "LIO.L\n",
      "TIFS.L\n",
      "AMGO.L\n",
      "GPOR.L\n",
      "CTY.L\n",
      "No financial data for CTY.L\n",
      "Could not find robur code\n",
      "AAF.L\n",
      "CEY.L\n",
      "CSH.L\n",
      "PNN.L\n",
      "IBST.L\n",
      "WMH.L\n",
      "CCR.L\n",
      "BOY.L\n",
      "SCT.L\n",
      "APAX.L\n",
      "FEV.L\n",
      "No financial data for FEV.L\n",
      "Could not find robur code\n",
      "UDG.L\n",
      "AVV.L\n",
      "JET.L\n",
      "RDW.L\n",
      "FRES.L\n",
      "GYS.L\n",
      "AGK.L\n",
      "SYNC.L\n",
      "CKN.L\n",
      "NRR.L\n",
      "FSJ.L\n",
      "GNS.L\n",
      "TRIG.L\n",
      "TBCG.L\n",
      "HOC.L\n",
      "FIN.L\n",
      "HTG.L\n",
      "HIK.L\n",
      "DLN.L\n",
      "TEP.L\n",
      "BBY.L\n",
      "INDV.L\n",
      "GLO.L\n",
      "SCIN.L\n",
      "SAGA.L\n",
      "KGF.L\n",
      "MRC.L\n",
      "SMP.L\n",
      "ICGT.L\n",
      "FDM.L\n",
      "CINE.L\n",
      "COA.L\n",
      "SSPG.L\n",
      "CHG.L\n",
      "HFG.L\n",
      "BYG.L\n",
      "BME.L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simondunkelman/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  app.launch_new_instance()\n",
      "/Users/simondunkelman/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/simondunkelman/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:42: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-17eac77a8237>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculating\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mUnixToDate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mdaily_ticker_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetDailyTickers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprice_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mquality_factor_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_factor_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_factor_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCalculateDailyFactors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdaily_ticker_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinancials_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprice_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrobur_codes_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mquality_factor_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_factor_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_factor_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquality_factor_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_factor_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_factor_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-152e80b45e7b>\u001b[0m in \u001b[0;36mCalculateDailyFactors\u001b[0;34m(ticker_list, unix_date, financials_df, price_df, robur_codes_df)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompany_financials\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mcompany\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompany\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcompany_financials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcompany_share_price\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'fh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mcompany_quality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompany\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEquityQuality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mcompany_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompany\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEquityValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mcompany_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompany\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEquitySize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-c85e2e69833e>\u001b[0m in \u001b[0;36mEquityQuality\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m                \u001b[0;34m'cash_flow_to_assets'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperating_cash_flow\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_assets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                \u001b[0;34m'debt_to_earnings'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_debt\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mebitda\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                \u001b[0;34m'asset_leverage'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_debt\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_assets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                }\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "for market in ['L']: #markets\n",
    "    # Load data\n",
    "    price_filename = './with_removals/' + market + '_price_data.csv'\n",
    "    price_data = pd.read_csv(price_filename)\n",
    "    # price_data.t = pd.to_datetime(price_data.t,unit='s')\n",
    "    financials_filename = './with_removals/' + market + '_financial_data.csv'\n",
    "    financials_data = pd.read_csv(financials_filename)\n",
    "    financials_data.period = pd.to_datetime(financials_data.period,format='%Y-%m-%d')\n",
    "    \n",
    "    # Create master dataframe for entire time series\n",
    "    ticker_list = list(set(price_data.ticker))\n",
    "    market_date_time_series = price_data.t.loc[price_data.ticker == GetLongestTimeSeriesTicker(ticker_list,price_data)]\n",
    "    \n",
    "    master_quality_factor_time_series = pd.DataFrame()\n",
    "    master_size_factor_time_series = pd.DataFrame()\n",
    "    master_value_factor_time_series = pd.DataFrame()\n",
    "    \n",
    "    # Get DF of financial data for single day of each stock\n",
    "#     test_date = 1596697200 # DEBUG\n",
    "#     test_date_list = [test_date] # DEBUG\n",
    "    for date in market_date_time_series:\n",
    "        print(\"Calculating\",UnixToDate(date))\n",
    "        daily_ticker_list = GetDailyTickers(price_data,date)\n",
    "        quality_factor_df, value_factor_df, size_factor_df = CalculateDailyFactors(daily_ticker_list,date,financials_data,price_data,robur_codes_map)\n",
    "        quality_factor_df, value_factor_df, size_factor_df = quality_factor_df.set_index('ticker'), value_factor_df.set_index('ticker'), size_factor_df.set_index('ticker')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker\n",
       "HILS.L    0.006785\n",
       "HSX.L     0.002335\n",
       "ASL.L     0.000015\n",
       "PHP.L     0.007254\n",
       "MDC.L     0.004613\n",
       "            ...   \n",
       "IWG.L     0.008333\n",
       "WIZZ.L    0.006275\n",
       "N91.L     0.003741\n",
       "CNA.L     0.005327\n",
       "IMI.L     0.006223\n",
       "Name: weight, Length: 203, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# daily_data\n",
    "z_score_test = WeightFactorConstituents(daily_data)\n",
    "z_score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
